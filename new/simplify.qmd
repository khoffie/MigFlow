---
title: Migration Distance How to model and why it matters
authors:
    name: Konstantin Hoffie
    affiliation: East-German
    roles: writing
    corresponding: true
engine: julia
execute:
  echo: false
  enabled: false
julia:
  exeflags: ["--project=/home/konstantin/code"]
  env: ["JULIA_NUM_THREADS=5"]
---

# Introduction
This document explains the model. The functional form, choice of
predictors, the underlying assumptions as well as insights to be
gained are laid out. First, the model is presented in its entirety,
then the individual components are introduced.

## The Model
**Model equation + tables of parameters and predictors**

## Overall functional form
Explain here why the model is multiplicative. Maybe also why pop and
dist state what can be expected and that density cheby and geo cheby
induce asymmetries.

```{julia}
#| label: libraries-functions
#| output: false

sr = true
using Revise, Distributions, StatsPlots, CSV, DataFrames, Random
using DataFramesMeta, Turing, SliceSampling, LogDensityProblems
using Serialization, Printf, Plots, Optimization, LaTeXStrings
using LinearAlgebra: I
using CategoricalArrays, ApproxFun, NamedArrays, KernelDensity, StatsBase
using Interpolations

include("../src/loadgermdata.jl")
include("src/estimation.jl")
include("src/fullmodel.jl")
include("src/othermodels.jl")
include("src/utils.jl")
include("src/diag.jl")
include("src/diagplots.jl")

```

```{julia}
#| label: load-data

ages = ["below18", "18-25", "25-30","30-50", "50-65", "above65"]
flows = read_flows("../data/FlowDataGermans.csv", .1, ages, 2000:2017)
flows = flows[(flows.agegroup .== "30-50") .& (flows.year .== 2017), :]

districts = CSV.read("../data/districts.csv", DataFrame)
add_lrd(districts)
flows = joinlrd(flows, districts)

```

## Populations

```{julia}

function plot_flows(df, groupcol, popcol)
    df = combine(groupby(df, groupcol), :flows => sum, popcol => unique)
    df = df[df.flows_sum .> 0, :]
    sp = string(popcol)
    scatter(log.(df[!,  sp * "_unique"]),
            log.(df.flows_sum),
            label = "", xlab = "log $sp")
end

function plot_totalflux(df)
    a = string(unique(df.agegroup)[1])
    y = string(unique(df.year)[1])
    p1 = plot(plot_flows(df, :fromdist, :frompop), ylab = "total outflux")
    p2 = plot(plot_flows(df, :todist, :topop), ylab = "total influx")
    plot(p1, p2, plot_title = "Populations and total flux\n$a, $y",
         plot_titlevspan = .2)
end

plot_totalflux(flows)

```

## Distance
Intuitively distance matters because a greater distance brings with it
certain inconveniences. The further I move the further I am away from
my friends and family, the more I have to adept to a new city, new
culture etc. Empirically it is also clear that distance is a very
important factor, inhibiting migrations (see @fig-distance).

```{julia}
#| label: fig-distance
#| fig.cap: caption
caption = "Observed distribution of migration distances and expected distribution if migrants would not respond to distance (expected). Both curves were obtained by a kernel density estimation. For the expected curve we assumed that people pick a destination randomly, with a probability proportional to it's population. The other three curves model the dependence on distance but differ in their assumptions. Gravity assumes a power law decay, linear assumes a linear decay and mixture assumes there are two populations: Distance sensitive, modeled as power law decay and distance insensitive, who do not respond to distance at all."

function plotdistances(mdat, out)
    kernel = Normal(0, 20)
    age = unique(mdat.agegroup)[1]
    year = unique(mdat.year)[1]
    main = "Distribution of distances, $age in $year"
    plot(distance_kde(mdat.dist, mdat.flows, kernel, "Observed", false),
         title = main)
    distance_kde(mdat.dist, out.preds, kernel, "Predicted", true)
    distance_kde(mdat.dist, mdat.frompop .* mdat.topop, kernel,
                 "Expected", true)
end

mdat = gen_mdat(flows, districts; ndc = 1, ngc = 1)
out = estimate(full, mdat)
plotdistances(mdat, out)

```

The above suggests that assuming two populations —distance sensitive
and distance insensitive— better describes the data. From a
theoretical perspective it helps to explain surprising facts about
reality: Why the decay is so fast between 50 and 200km and why at the
same time relatively many migrate across distances of 300km and more.

```{julia}
#| label: fraction-insensitive
#| output: false
#| fig.cap: Fraction of distance insensitive moves as function of distance, in percent.

function estiml(flows, districts, ds)
    mdat = gen_mdat(flows, districts; distscale = ds,
                    ndc = 1, ngc = 1)
    l = estimate(distonly, mdat).out["l"]
    return l
end

dscales = Float64.([1 : 1 : 10; 11 : 10 : 201; 202 : 50 : 803])
ls = [estiml(flows, districts, ds) for ds in dscales]
plot(dscales, ls, label = "",
     xlab = "Distance in km",
     ylab = "Fraction",
     title = "Fraction of distance insensitive moves")

```

```{julia}
#| label: predictl

logistic(x, a, b, c = 0, L = 1) = L ./ (1 .+ exp.( .- (a .+ b .* (x  .- c))))

function plotlogreg(res, chn)
    plot(res.dist, res.l, label = "l estimated in mixture model")
    a = mean(chn[:a][700:end])
    b = mean(chn[:b][700:end])
    c = mean(chn[:c][700:end])
    regline = logistic(res.dist, a, b, c, 100)
    plot!(res.dist, regline,
          title = "l: Fraction of distance insensitive",
          xlab = "Distance in km",
          ylab = "l, Fraction of insensitive",
          label = "l explained in logistic regression")
end

@model function predict_l(dist, l)
    a ~ Normal(0, 5)
    b ~ Normal(0, 5)
    s ~ Gamma(1, 1)

    l = log.(l)
    m = logistic(dist, a, b, 0, 1)
    l ~ arraydist(Normal.(m, s))
    return m
end


mdl = predict_l(res.dist, res.ratio)
chn = Turing.sample(mdl, NUTS(), 1000)
plot(chn)
res.preds = generated_quantities(mdl, chn[end, :, :])[1]
plot(res.dist, res.preds)
res
chn
plotlogreg(res, chn)

res.ratio = res.l ./ (100.0 .- res.l)
plot(res.dist, res.ratio)
plot!(res.dist, res.l)
```

Let's now estimate the fraction of distance insensitve migrants in the
population. That is, each migrant $i_{od}$ belongs either to distance
sensitive migrants $S$ or to distance insensitive migrants $S^c$ and
we want to estimate $P(i \in S^c)$. The fraction of insensitive
migrants at a certain distance, $\hat{l}$, is an estimate for the true
fraction of insensitive migrants at a certain distance, $l := P(i \in
S^c | D(i) = x)$. Thus, $l$ is a conditional probability and by
integrating over $[D_1, D_2]$ we can estimate how many migrants that
moved between $D_1$ and $D_2$km are insensitive.

$$
\int_{D_1}^{D_2}l_i(x)dP_D(x) = \int_{D_1}^{D_2}l_i(x)f(x)dx 
$$

where $f$ is the density of $D$. Of particular interest is the
integral over $[\min(D), \max(D)]$ since this estimates the fraction
of insensitive migrants.

```{julia}

interp = linear_interpolation(Float64.(res.dist), res.l)
weights = flows.flows ./ sum(flows.flows)
di = StatsBase.wsample(flows.dist, weights, 10^3)

function plotfrac(l::AbstractExtrapolation, di::Vector{Int};
                  dmin::Signed = minimum(di),
                  dmax::Signed = maximum(di),
                  add::Bool = true, lbl::String = "")
    frac = l.(di[di .> dmin .&& di .< dmax])
    f = add == true ? plot! : plot
    p = f(kde(frac), label = lbl)
    display(p)
    return frac
end

```

```{julia}
#| label: calc-frac-2017

function retinterp(model, age::String, year::Int)
    println("Starting interpolation for $age and $year")
    flows, geog = load_data("../data", 0.1, age, year);
    res, p = estimate_l(model, flows)
    interp = linear_interpolation(Float64.(res.dist), res.l)
    return res.dist, res.l, interp
end

results = [(agegroup = g, out = retinterp(distonly, g, 2017)) for g in ages]

p = plot()
results[1].interp
[plotfrac(results[i].out[3], di, lbl = results[i].agegroup)
 for i in eachindex(results)]

p = plot(xlab = "Distance in km", ylab = "Fraction of insensitve, %")
[plot!(results[i].out[1],
       results[i].out[2],
       label = results[i].agegroup) for i in eachindex(ages)]
p

p = plot(xlab = "Fraction of insensitive", ylab = "Density")
[plotfrac(results[i].out[3], di, lbl = results[i].agegroup) for i in eachindex(ages)]


```

## Estimate model with density

```{julia}



args = Dict(
    :flows => flows.flows,
    :fp => flows.frompop,
    :tp => flows.topop,
    :di => flows.dist
)

grav = estimate(gravity, args, [-20, 10], [0, 100])
grav[1]


function fitdistdens(model, flows, ndc)
    args = Dict(
        :flows => flows.flows,
        :fp => flows.frompop,
        :tp => flows.topop,
        :di => flows.dist,
        :fd => flows.fromdens,
        :td => flows.todens,
        :ndenscoefs => ndc,
        :densmin => minimum(flows.fromdens),
        :densmax => maximum(flows.todens)
    )

    ## a, c, l, d0, kd
    lb = [-20, 10, 0, 1, fill(-10, ndc)...]
    ub = [0, 100, 99, 100, fill(10, ndc)...]
    out = estimate(model, args, lb, ub)
    kds = out[1][startswith.(names(out[1])[1], "kd")]
    evaldensitycheby(kds, args[:densmin], args[:densmax])
    return out
end

out = fitdistdens(distdens, flows, 2)
out[1]

```

